---
layout: default
title: Keynotes
rank: 3
---

## <span style="color:#267CB9"> Keynotes</span>

### Anne Lauscher
*University of Hamburg*

#### Once Upon a Bias: A Fairy Tale of Gender in Language Technology

**Abstract**

This is a story of dreams, detours, and (of course) data. In this keynote, I tell the tale of how a research community—our community—set out to create gender-fair language technologies. Along the way, we met dragons like stereotypical occupations, default male pronouns, and cisnormative datasets. We tried to rescue invisible identities. We met allies, too: other communities and other research disciplines. Drawing on my own memories of our adventures I will reflect upon the challenges we tackled and the drawbacks that remain. Finally, I will open the next chapter and invite you to take a look into the future.

---

### Maarten Sap
*Carnegie Mellon University (CMU) & Allen Institute for AI (AI2)*

#### Responsible AI for Diverse Users and Cultures

**Abstract**

AI systems and language technologies are increasingly developed and deployed onto users of diverse genders and cultures. Yet, they still lack contextual and cultural awareness, and are unilaterally pushed onto many users that do not necessarily want them. In this talk, I will discuss some ongoing projects towards responsible AI development for diverse users and cultures.
I will first discuss the CobraFrames formalism, a method to enhance the reasoning of models for offensive speech grounded in social contexts such as speaker and listener identities. Then, I will discuss MC-Signs, a novel benchmark to measure the cultural awareness of multimodal AI systems with respect to culturally offensive gestures. Finally, I will conclude with a study on AI acceptability, showing that lay people's opinions about when and where AI should be used varies depending on their gender, AI literacy, and more. I will conclude with some future directions towards responsible and prosocial AI.
